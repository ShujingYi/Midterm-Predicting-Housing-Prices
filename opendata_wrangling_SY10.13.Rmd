---
title: "Predicting Housing Prices"
author: "Shujing Yi & Yuehui Gong"
date: '2022-10-10'
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

```{r, include=FALSE}
## Quick fix for stargazer <= 5.2.3 is.na() issue with long model names in R >= 4.2
# Unload stargazer if loaded
#detach("package:stargazer",unload=T)
# Delete it
remove.packages("stargazer")
# Download the source
download.file("https://cran.r-project.org/src/contrib/stargazer_5.2.3.tar.gz", destfile = "stargazer_5.2.3.tar.gz")
# Unpack
untar("stargazer_5.2.3.tar.gz")
# Read the sourcefile with .inside.bracket fun
stargazer_src <- readLines("stargazer/R/stargazer-internal.R")
# Move the length check 5 lines up so it precedes is.na(.)
stargazer_src[1990] <- stargazer_src[1995]
stargazer_src[1995] <- ""
# Save back
writeLines(stargazer_src, con="stargazer/R/stargazer-internal.R")
# Compile and install the patched package
install.packages("stargazer", repos = NULL, type="source")
```

# Introduction

As Zillow has realized that its housing market predictions are not as
accurate as they could be because they do not factor in enough local
intelligence in Mecklenburg, this project is to improve Zillow's housing
market predictions for Mecklenburg.

To build a better housing price prediction regression model, our model
includes three types of variables: external amenities, internal
characteristics of houses from the given housing price dataset, and
services from open data source, and spatial factors.


## Setup

```{r setup_set}

# You can set some global options for knitting chunks

knitr::opts_chunk$set(echo = TRUE)

# Load some libraries
library(tidyverse)
library(raster)
library(tidycensus)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
library(stargazer)

# functions and data directory
root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"

source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")

palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
```

# Data Wrangling and Feature Engineering

The given housing price dataset includes the housing price and internal
characteristics information for each housing point. It is input as the
base dataset for further feather engineering.

```{r, results='hide'}
sale <- 
  st_read("data/studentData.geojson") %>%
  st_transform('ESRI:102286')

```



```{r, results='hide'}
Mecklenberg <- 
  st_read("data/zipcode/zipcode.shp") %>%
  st_transform('ESRI:102286')
```

The following map visualize the distribution of housing points and their
prices, which is represented in color.

It is clear the housing price distribution shows spatial clustering: the houses with high price, represented in orange, mainly distribute in the southern neighborhoods and other clusters near the county boundary.

```{r}
ggplot() +
  geom_sf(data=Mecklenberg,fill = "grey40", color = "grey10",size= 0.7)+
  geom_sf(data = sale, aes(colour = q5(as.numeric(price))), 
          show.legend = "point", size = .75) +
  scale_colour_manual(values = palette5,
                   labels=qBr(sale,"price"),
                   name="Quintile\nBreaks") +
  labs(title="Home Price, Mecklenburg")

```

## External Amenities

The first part of variables our model is to use the external
amenities, the proximity to which could add value to houses. To get the
data, we are using the open data portal for Mecklenburg.
(<http://maps.co.mecklenburg.nc.us/openmapping/data.html>)

Our model is considering the following amenities and services: 
-Public Transportation: bus stop, station 
-Public Amenities: park, school
-Potential negative factors: homeless shelter, flood, Landfill


### Bus Stop

As part of the public transportation system, being close to bus stops might add value to housing price. The following map shows the bus stops in Mecklenburg. 

```{r, results='hide'}
busstop <- st_read("data/cats_busstops/CATS_BusStops.shp") #%>%
#st_transform(st_crs(tracts20))
ggplot() +
 geom_sf(data=Mecklenberg,fill = "white", color = "grey60",size= 0.5)+
  geom_sf(data = busstop,size= 0.3)+
    labs(title = "Bus Stops, Mecklenburg")
  
```

The distance from each house to the nearest bus stop is calculated as “bus_nn1”, which could be one important external variables for our model.

```{r}
sale <-
  sale %>% 
    mutate(bus_nn1 = nn_function(st_coordinates(sale), st_coordinates(busstop), 1))

```

### Station

Similar to bus stops, metro station is a significant part of transportation service. The following map shows the station stops in Mecklenburg and “station_nn1” is measured as the nearest distance from house to metro station.

```{r, results='hide'}
station<- st_read("data/station_merge/station_merge.shp") 
ggplot() +
 geom_sf(data=Mecklenberg,fill = "white", color = "grey60",size= 0.5)+
    geom_sf(data = station) +
    labs(title = "Stations, Mecklenburg")

```

```{r}
sale <-
  sale %>% 
    mutate(station_nn1 = nn_function(st_coordinates(sale), st_coordinates(station), 1))

```

### Park

Park is serving as a public amenities for people’s daily recreation, as is shown in the following density map, and the distance to park could be considered. Thus, we are calculating the distance to the nearest park as “park_nn1” and mean distance to the 3 nearest parks as “park_nn3”. Further analysis would be down to select the more effective variable.

```{r, results='hide'}
park <- st_read("data/park_locations/Park_Locations.shp") %>%
              st_transform(st_crs(Mecklenberg)) 


ggplot() + geom_sf(data=Mecklenberg,fill = "white", color = "grey60",size= 0.5)+
  stat_density2d(data = data.frame(st_coordinates(park)), 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.01, bins = 40, geom = 'polygon') +
  scale_fill_gradient(low = "#25CB10", high = "#FA7800", 
                      breaks=c(0.000000003,0.00000003),
                      labels=c("Minimum","Maximum"), name = "Density") +
  scale_alpha(range = c(0.00, 0.35), guide = FALSE) +
  labs(title = "Density of Parks, Mecklenburg") 

```



```{r}
sale <-
  sale %>% 
    mutate(park_nn1 = nn_function(st_coordinates(sale), st_coordinates(park), 1),
           park_nn3 = nn_function(st_coordinates(sale), st_coordinates(park), 3))

```

### School

Also as an important amenity, we are using public school point data, including elementary, middle, high school and charter school. 
It might be more helpful to think of school district data, but it is not available from the open data source.

```{r, results='hide'}
school_public <- st_read("data/cms_schools/CMS_Schools.shp") %>%
              st_transform(st_crs(Mecklenberg)) %>%
  dplyr::select(city, address)

school_charter <- st_read("data/schools_charter/Schools_Charter.shp") %>%
              st_transform(st_crs(Mecklenberg)) %>%
    dplyr::select(city, address)


school<-rbind(school_public,school_charter)

ggplot()+
    geom_sf(data=Mecklenberg,fill = "white", color = "grey60",size= 0.5)+  
  geom_sf(data=school)+
    labs(title = "Public Schools in Mecklenburg") 
```

“school_nn1”, “school_nn2”, “school_nn3” are calculated as the mean distance to the nearest, 2 nearest and 3 nearest schools from each housing points.

```{r}
sale <-
  sale %>% 
    mutate(school_nn1 = nn_function(st_coordinates(sale), st_coordinates(school), 1),
   school_nn2 = nn_function(st_coordinates(sale), st_coordinates(school), 2),   
   school_nn3 = nn_function(st_coordinates(sale), st_coordinates(school), 3))
```

### Homeless Shelter

Homeless shelters is part of the potential negative factors, which are mainly located at the center of Mecklenberg county. Thus, the proximity to homeless shelter is calculated as “homelessshelter_nn1”.

```{r, results='hide'}
homelessshelter <- st_read("data/homeless_shelters/Homeless_Shelters.shp") %>%
              st_transform(st_crs(Mecklenberg)) 
ggplot() +
  geom_sf(data=Mecklenberg,fill = "white", color = "grey60",size= 0.5)+
  geom_sf(data = homelessshelter, fill = "red")+ 
  labs(title = "Homeless Shelter in Mecklenburg")



sale <-
  sale %>% 
    mutate(homelessshelter_nn1 = nn_function(st_coordinates(sale), st_coordinates(homelessshelter), 1))
```

### Landfill

Another potential negative factor which might impact the housing price is the landfill. The landfill parcels are visualized in the map.

```{r, results='hide'}
landfill <- st_read("data/landfills/Landfills.shp") %>%
              st_transform(st_crs(Mecklenberg)) 


ggplot() +
  geom_sf(data=Mecklenberg,fill = "white", color = "grey60",size= 0.5)+  
  geom_sf(data = landfill, fill = "red", color = "transparent") +
   labs(title = "Landfill in Mecklenburg") 

```

To do the feature engineering, we use st_centroid to extract the center points and then calculate the nearest distance from houses to landfill center points.

```{r}
sale <-
  sale %>% 
    mutate(landfill = nn_function(st_coordinates(sale), st_coordinates(st_centroid(landfill)), 1))
```

### Floodplain

We find flooding might be another concern when people are buying their houses, which means whether or not the houses are within the 100 year floodplain could a significant variable for our model. The map shows the 100 year floodplain along the water way.

```{r, results='hide'}
flood100y <- st_read("data/femaexisting_100yr_floodplain/FEMAExisting_100yr_Floodplain.shp") %>%
              st_transform(st_crs(Mecklenberg)) 
ggplot() +
  geom_sf(data=Mecklenberg,fill = "white", color = "grey60",size= 0.5)+  
  geom_sf(data = flood100y, fill = "dark blue",color="transparent") +
  labs(title = "100 year Floodplain in Mecklenburg") 
```

Then we map the houses within the floodplain in red in the following map. We create a binary variable called “flood100y” to assign “1” to houses within the floodplain and “0” to houses that will not be impacted by 100 year flood.

```{r}
salegroup <- 
  rbind(
    sale[flood100y,] %>%
      st_drop_geometry() %>%
      left_join(sale) %>%
      st_sf() %>%
      mutate(flood100y = 1),
   sale[flood100y, op = st_disjoint] %>%
      st_drop_geometry() %>%
      left_join(sale) %>%
      st_sf() %>%
      mutate(flood100y = 0))

salegroup <- salegroup[!duplicated(salegroup$musaID), ]  

```

```{r}
floodpt<-
  salegroup %>%
  filter(flood100y == 1)

ggplot() +
  geom_sf(data=Mecklenberg,fill = "white", color = "grey60",size= 0.5)+  
  geom_sf(data = flood100y, fill = "dark blue",color="transparent") +
     geom_sf(data = salegroup,  col = "grey80",
          show.legend = "point", size = .2) +
  geom_sf(data = floodpt, col = "red",
          show.legend = "point", size = .7) +
  labs(title = "Houses within 100 year Floodplain in Mecklenburg") 


```

## Internal Characteristics

The second part of variables for our model is the internal characteristics, which are the variables of the housing characteristics from the given housing data.

The following is the variables to consider:
-Heated area
-Bedrooms
-Full baths
-Half baths
-Housing age
-Housing story height
-Fire place number
-Foundation types
-Heated fuel types
-Architecture types
-Units
-Account types

In this part, we are doing feature engineering to either transform numeric variables to categorical variables or recategorize the categorical variables to increase the model accuracy.

### Categorical Bar Plot

To identify the categorical variables which have high correlation with price, we first make the bar plots showing price as a function of categorical variables.

```{r fig.height=8, fig.width=12}
st_drop_geometry(salegroup) %>% 
  dplyr::select(price, descbuildi, storyheigh, aheatingty, heatedfuel,actype,extwall,foundation, bldggrade,
                ) %>%
  filter(price <= 1000000) %>%
  gather(Variable, Value, -price) %>% 
   ggplot(aes(Value, price)) +
     geom_bar(position = "dodge", stat = "summary", fun.y = "mean") +
     facet_wrap(~Variable, ncol = 4, scales = "free") +
     labs(title = "Price as a function of\ncategorical variables", y = "Mean_Price") +
     plotTheme() + theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

It shows that the variables of architecture type, building grade, heated fuel type and story height are all correlated with sale price and they can be our potential variables.



### Age

One key characteristics of a house to consider is its age.  We first calculate the age (age = 2022 - yearbuilt).

```{r}
salegroup <- 
  salegroup %>%
  mutate(age = 2022 - yearbuilt)
```


```{r}
s <-salegroup %>% 
  filter(age <= 200) 
histogram(s$age,main="Housing Age Histogram",breaks=40,col = c("grey50"))

```

The age now is a numeric variable, which doesn’t correlate strongly with the price. To transform them into categorical variables, we want to identify the different ranges to categorize the age variable, so we make this histogram. Based on the age histogram, we decide to categorize the age into four ranges in “age.cat” variable:

age >= 0 & age <15  ~ "Up to 15yrs",
age >= 15 & age < 50  ~ "15-50yrs",
age >= 50 & age < 75  ~ "50-75yrs",                   
age >= 75  ~ "75+yrs"

```{r}
salegroup <- 
  salegroup %>%
  mutate(age.cat = case_when(
                  age >= 0 & age <15  ~ "Up to 15yrs",
                  age >= 15 & age < 50  ~ "15-50yrs",
                  age >= 50 & age < 75  ~ "50-75yrs",                   
                  age >= 75  ~ "75+yrs"),)
```

### Story Height

We think it might be helpful to recategorize the story height class. So we use “recode” to get the “story.cat” variable of 5 class:

"1.0 STORY"= "1story","1 STORY"= "1story"
"1.5 STORY" = "2story", "2.0 STORY" = "2story","BI-LEVEL"="2story","SPLIT LEVEL"="2story"
"2.5 STORY"="3story","3.0 STORY"="3story"
"CAPE COD"="other","RANCH W/BSMT"="other"
">=4story "

```{r,results='hide'}
glimpse(s$storyheigh)


salegroup$story.cat <- recode(salegroup$storyheigh,"1.0 STORY"= "1story","1 STORY"= "1story", "1.5 STORY" = "2story", "2.0 STORY" = "2story","BI-LEVEL"="2story","SPLIT LEVEL"="2story","2.5 STORY"="3story","3.0 STORY"="3story","CAPE COD"="other","RANCH W/BSMT"="other")

```

##  Spatial Factors

### Census Tract

To take spatial clustering into consideration, we then use census tract data and neighborhood effect as the spatial factors to help the model better understand the spatial clustering.

By importing the census tract data, we collect the total population, white population, female bachelors, male bachelors, median income, median rent, total poverty.

We then calculate the variables of white population percentage, bachelor percentage, poverty percentage to make it easier to do the comparison among census tracts.

```{r, results='hide'}
census_api_key("a78f5d0c0fd577cd3f16136b5a87d6ecdb62ffba", overwrite = TRUE)

tracts <-  
  get_acs(geography = "tract",
          variables = c("B25026_001E","B02001_002E",
                        "B15001_050E","B15001_009E",
                        "B19013_001E", "B25058_001E",
                        "B06012_002E"), 
          year=2020, state="NC",
          county="Mecklenburg County", geometry=TRUE) %>% 
  st_transform('ESRI:102286')

```

```{r}
tracts <- 
  tracts %>%
  dplyr::select( -NAME, -moe) %>%
  spread(variable, estimate) %>%
  rename(TotalPop = B25026_001, 
         Whites = B02001_002,
         FemaleBachelors = B15001_050, 
         MaleBachelors = B15001_009,
         MedHHInc = B19013_001, 
         MedRent = B25058_001,
         TotalPoverty = B06012_002)

tracts <- 
  tracts %>%
  mutate(pctWhite = ifelse(TotalPop > 0, Whites / TotalPop, 0),
         pctBachelors = ifelse(TotalPop > 0, ((FemaleBachelors + MaleBachelors) / TotalPop), 0),
         pctPoverty = ifelse(TotalPop > 0, TotalPoverty / TotalPop, 0)) %>%
  dplyr::select(-Whites,-FemaleBachelors,-MaleBachelors,-TotalPoverty)
```

```{r}
ggplot()+
  geom_sf(data = tracts, fill = "white", color = "black")+
  geom_sf(data=salegroup, 
          show.legend = "point", size= 0.1) +
  labs(title = "Mecklenburg Census Tracts") +
  theme(plot.title = element_text(size=22))
```

```{r}

A2<-
  ggplot() +
  geom_sf(data = tracts, aes(fill = pctWhite)) +
  labs(title = "White Percentage", subtitle = "Mecklenburg, 2020") +
  theme(plot.title = element_text(size=22))
A3<-
  ggplot() +
  geom_sf(data = tracts, aes(fill = MedHHInc)) +
  labs(title = "Median Income", subtitle = "Mecklenburg, 2020") +
  theme(plot.title = element_text(size=22))
grid.arrange(A2,A3, nrow = 1)
```

So following is the spatial variables for our model:

-White percentage 
-Bachelor percentage
-Poverty percentage 
-Median income
-Median rent



```{r}
salegroup<-st_intersection(salegroup,tracts)

```

```{r}
salegroup<-st_intersection(salegroup,Mecklenberg)
```



## Table of summary statistics


```{r}
stargazer(as.data.frame(salegroup[c("price","heatedarea","bedrooms","fullbaths","halfbaths","numfirepla","foundation","heatedfuel","actype","units","accounttyp","shape_Area")]), type="text", 
          title="Internal Characteristics", digits=1)
```
```{r}
stargazer(as.data.frame(salegroup[c("park_nn1","homelessshelter_nn1","landfill","flood100y","school_nn1","bus_nn1","station_nn1")]), type="text", 
          title="Amenities/public Services", digits=1)
```


```{r}
stargazer(as.data.frame(salegroup[c("TotalPop","pctWhite","pctBachelors","pctPoverty", "MedHHInc")]), type="text", 
          title="Spatial Structure", digits=1)
```


## Home Price Correlation Scatter Plots

To understand how some of the continuous variables correlate with housing price, we get the correlation scatter plots.

```{r}
st_drop_geometry(salegroup) %>% 
  dplyr::select(price,park_nn1,landfill,flood100y,MedHHInc) %>%
  filter(price <= 1000000) %>%
  gather(Variable, Value, -price) %>% 
  
   ggplot(aes(Value, price)) +
     geom_point(size = .5) + geom_smooth(method = "lm", se=F, colour = "#FA7800") +
     facet_wrap(~Variable, ncol = 2, scales = "free") +
     labs(title = "Price as a function of continuous variables") +
     plotTheme()
```

For the 100 year flood and landfill, it makes sense that the further distance to landfills the higher housing price will be and but it is strange to see that the houses in floodplain have slightly higher price.

For the park, the scatter plot shows that the closer to the parks, the more expensive the houses would be, which proves that parks could be an attractive public amenity. It is also not surprising that median income of census tract has high correlation with housing price spatially. 


## Correlation Matrix

Correlation matrix is produced to see the relationship between the continuous variables.Three separate correlation matrix are made for each part of our variables. To further simplify the correlation plot, only one variable is kept for each amenity.

```{r}
numericVars <- 
  select_if(st_drop_geometry(salegroup), is.numeric) %>% na.omit()%>%
  dplyr::select(price,heatedarea,bedrooms,fullbaths,numfirepla,units)

ggcorrplot(
  round(cor(numericVars), 1), 
  p.mat = cor_pmat(numericVars),
  colors = c("#25CB10", "white", "#FA7800"),
  type="lower",
  insig = "blank") +  
    labs(title = "Correlation across numeric variables: Internal Characteristics") 
```
```{r}
numericVars <- 
  select_if(st_drop_geometry(salegroup), is.numeric) %>% na.omit()%>%
  dplyr::select(price,park_nn1,homelessshelter_nn1,landfill,flood100y,school_nn1,bus_nn1,station_nn1)

ggcorrplot(
  round(cor(numericVars), 1), 
  p.mat = cor_pmat(numericVars),
  colors = c("#25CB10", "white", "#FA7800"),
  type="lower",
  insig = "blank") +  
    labs(title = "Correlation across numeric variables: External Amenities") 
```
```{r}
numericVars <- 
  select_if(st_drop_geometry(salegroup), is.numeric) %>% na.omit()%>%
  dplyr::select(price,TotalPop,pctWhite,pctBachelors,pctPoverty, MedHHInc)

ggcorrplot(
  round(cor(numericVars), 1), 
  p.mat = cor_pmat(numericVars),
  colors = c("#25CB10", "white", "#FA7800"),
  type="lower",
  insig = "blank") +  
    labs(title = "Correlation across numeric variables: Census Tract data") 
```


# Methods

After selecting all the "MODELLING" data from our dataset, the data is split into training and test datasets,, which is 60% and 40% respectively. Models will be trained on the training set and tested on the latter to see how accurate our model is.


# Modeling
```{r}
salegroup_challenge <- salegroup %>%
  filter (salegroup$toPredict == "CHALLENGE")
salegroup <- salegroup %>%
  filter (salegroup$toPredict == "MODELLING")

```

## OLS regression

Outer:homelessshelter_nn1,park_nn1,park_nn3,landfill,flood100y,school_nn1,school_nn2,school_nn3,bus_nn1,station_nn1
Census:TotalPop,pctWhite,pctBachelors,pctPoverty,MedHHInc,MedRent

```{r}
reg1 <- lm(price ~ ., data = st_drop_geometry(salegroup) %>% 
                                 dplyr::select(price, zip,heatedarea, bedrooms, 
                                               age.cat,storyheigh,fullbaths, halfbaths,
                                               numfirepla,foundation,heatedfuel,units,accounttyp, park_nn1,homelessshelter_nn1,landfill,flood100y,school_nn1,bus_nn1,station_nn1,bldggrade,
                                               TotalPop,pctWhite,pctBachelors,pctPoverty,MedHHInc,shape_Area))
summary(reg1)
```

## Cross validation

```{r}
inTrain <- createDataPartition(
              y = paste(salegroup$storyheigh,salegroup$age.cat,salegroup$heatedfuel, salegroup$actype,salegroup$foundation,salegroup$accounttyp), 
              p = .60, list = FALSE)
Mecklenberg.training <- salegroup[inTrain,] 
Mecklenberg.test <- salegroup[-inTrain,]  
```

```{r}
reg.training <- lm(price ~ ., data = st_drop_geometry(Mecklenberg.training) %>% 
                                 dplyr::select(price, heatedarea, bedrooms, 
                                               age.cat,storyheigh,fullbaths, halfbaths,
                                               numfirepla,foundation,heatedfuel,units,accounttyp, park_nn1,homelessshelter_nn1,landfill,flood100y,school_nn1,bus_nn1,station_nn1,bldggrade,
                                               TotalPop,pctWhite,pctBachelors,pctPoverty,MedHHInc,shape_Area))
summary(reg.training)
```

## Test Set

```{r}
Mecklenberg.test <-
  Mecklenberg.test %>%
  mutate(Regression = "Baseline Regression",
         SalePrice.Predict = predict(reg.training, Mecklenberg.test),
         SalePrice.Error = SalePrice.Predict - price,
         SalePrice.AbsError = abs(SalePrice.Predict - price),
         SalePrice.APE = (abs(SalePrice.Predict - price)) / SalePrice.Predict)%>%
  filter(price < 5000000) 
```

```{r}
ggplot() +
  geom_sf(data=Mecklenberg,fill = "grey40", color = "grey10",size= 0.7)+
  geom_sf(data = Mecklenberg.test, aes(colour = q5(as.numeric(SalePrice.AbsError))), 
          show.legend = "point", size = .75) +
  scale_colour_manual(values = palette5,
                   labels=qBr(sale,"price"),
                   name="Quintile\nBreaks") +
  labs(title="Home Price Absolute Error, Mecklenberg") +
  mapTheme()
```

```{r}
fitControl <- trainControl(method = "cv", number = 100)
set.seed(825)

reg.cv <- 
  train(price ~ ., data = st_drop_geometry(salegroup) %>% 
                                dplyr::select(price, heatedarea, bedrooms, 
                                               age.cat,storyheigh,fullbaths,halfbaths,
                                               numfirepla,foundation,heatedfuel,units,accounttyp, park_nn1,homelessshelter_nn1,landfill,flood100y,school_nn1,bus_nn1,station_nn1,bldggrade,
                                               TotalPop,pctWhite,pctBachelors,pctPoverty,MedHHInc,shape_Area), 
     method = "lm", trControl = fitControl, na.action = na.pass)

reg.cv
```

```{r}
reg.cv$resample[1:5,]
```

```{r goodness_metrics, message = FALSE, warning = FALSE}
dplyr::select(reg.cv$resample, -Resample) %>%
  gather(metric, value) %>%
  left_join(gather(reg.cv$results[2:4], metric, mean)) %>%
  ggplot(aes(value)) + 
    geom_histogram(bins=35, fill = "#FF006A") +
    facet_wrap(~metric,scales = "free_x") +
    geom_vline(aes(xintercept = mean), colour = "#981FAC", linetype = 3, size = 1.5) +

    labs(x="Goodness of Fit", y="Count", title="CV Goodness of Fit Metrics",
         subtitle = "Across-fold mean reprented as dotted lines")

```

## Spatial Correlation of error

```{r}
coords.test <- st_coordinates(Mecklenberg.test) 

neighborList.test <- knn2nb(knearneigh(coords.test, 5))

spatialWeights.test <- nb2listw(neighborList.test, style="W")

Mecklenberg.test$lagPrice <- lag.listw(spatialWeights.test, Mecklenberg.test$price)
Mecklenberg.test$lagPriceError<-lag.listw(spatialWeights.test, Mecklenberg.test$SalePrice.Error, NAOK = TRUE)

#Mecklenberg.test %>% 
  #mutate(lagPriceError = lag.listw(spatialWeights.test, SalePrice.Error, NAOK = TRUE)) %>%
  #ggplot(aes(lagPriceError, SalePrice.Error))

```

```{r}
ggplot(Mecklenberg.test, aes(x=lagPrice, y=price)) +
  geom_point(colour = "#FA7800") +
  geom_smooth(method = "lm", se = FALSE, colour = "#25CB10") +
  labs(title = "Price as a function of the spatial lag of price",
       caption = "Figure 4.2",
       x = "Spatial lag of price (Mean price of 5 nearest neighbors)",
       y = "Sale Price") +
  plotTheme()
```

```{r}
ggplot(Mecklenberg.test, aes(x=lagPriceError, y=price)) +
  geom_point(colour = "#FA7800") +
  geom_smooth(method = "lm", se = FALSE, colour = "#25CB10") +
  labs(title = "Error as a function of the spatial lag of price",
       caption="Figure 4.3",
       x = "Spatial lag of errors (Mean error of 5 nearest neighbors)",
       y = "Sale Price") +
  plotTheme()
```

## Moran's

```{r}
moranTest <- moran.mc(Mecklenberg.test$SalePrice.Error, 
                      spatialWeights.test, nsim = 999, na.action=na.omit)

ggplot(as.data.frame(moranTest$res[c(1:999)]), aes(moranTest$res[c(1:999)])) +
  geom_histogram(binwidth = 0.01) +
  geom_vline(aes(xintercept = moranTest$statistic), colour = "#FA7800",size=1) +
  scale_x_continuous(limits = c(-1, 1)) +
  labs(title="Observed and permuted Moran's I",
       subtitle= "Observed Moran's I in orange",
       x="Moran's I",
       y="Count") +
  plotTheme()
```

## Accounting for neighborhood

```{r}
# Errors by neighborhood
left_join(
  st_drop_geometry(Mecklenberg.test) %>%
    group_by(zip) %>%
    summarize(meanPrice = mean(price, na.rm = T)),
  mutate(Mecklenberg.test, predict.fe = 
                        predict(lm(price ~ zip, data = Mecklenberg.test), 
                        Mecklenberg.test)) %>%
    st_drop_geometry %>%
    group_by(zip) %>%
      summarize(meanPrediction = mean(predict.fe))) %>%
      kable() %>% kable_styling()
```

```{r}
reg.nhood <- lm(price ~ ., data = as.data.frame(Mecklenberg.training) %>% 
                                 dplyr::select(zip, price, heatedarea, bedrooms, 
                                               age.cat,storyheigh,fullbaths,halfbaths,
                                               numfirepla,foundation,heatedfuel,units,accounttyp, park_nn1,homelessshelter_nn1,landfill,flood100y,school_nn1,bus_nn1,station_nn1,bldggrade,
                                               TotalPop,pctWhite,pctBachelors,pctPoverty,MedHHInc,shape_Area))

Mecklenberg.test.nhood <-
  Mecklenberg.test %>%
  mutate(Regression = "Neighborhood Effects",
         SalePrice.Predict = predict(reg.nhood, Mecklenberg.test),
         SalePrice.Error = SalePrice.Predict- price,
         SalePrice.AbsError = abs(SalePrice.Predict- price),
         SalePrice.APE = (abs(SalePrice.Predict- price)) / price)%>%
  filter(price < 5000000)
```

```{r}
summary(reg.nhood)
```

## Accuracy of the neighborhood mode

```{r}
bothRegressions <- 
  rbind(
    dplyr::select(Mecklenberg.test, starts_with("price"), Regression, zip, SalePrice.Predict,SalePrice.Error,SalePrice.AbsError,SalePrice.APE) ,
    dplyr::select(Mecklenberg.test.nhood, starts_with("price"), Regression, zip, SalePrice.Predict, SalePrice.Error,SalePrice.AbsError,SalePrice.APE))   
```

```{r}

st_drop_geometry(bothRegressions) %>% 
   mutate_if(is.numeric, ~ifelse(abs(.) == Inf,NA,.))%>% 
  gather(Variable, Value, -Regression, -zip) %>%
  filter(Variable == "SalePrice.AbsError" | Variable == "SalePrice.APE") %>%
  group_by(Regression, Variable) %>%
    summarize(meanValue = mean(Value, na.rm = T)) %>%
    spread(Variable, meanValue) %>%
    kable()
```

```{r}
bothRegressions %>%
  dplyr::select(SalePrice.Predict, price, Regression) %>%
    ggplot(aes(price, SalePrice.Predict)) +
  geom_point() +
  stat_smooth(aes(price, price), 
             method = "lm", se = FALSE, size = 1, colour="#FA7800") + 
  stat_smooth(aes(SalePrice.Predict, price), 
              method = "lm", se = FALSE, size = 1, colour="#25CB10") +
  facet_wrap(~Regression) +
  labs(title="Predicted sale price as a function of observed price",
       subtitle="Orange line represents a perfect prediction; Green line represents prediction") +
  plotTheme()


```

```{r}
  
st_drop_geometry(bothRegressions) %>%
  group_by(Regression, zip) %>%
  summarize(mean.MAPE = mean(SalePrice.APE, na.rm = T)) %>%
  ungroup() %>% 
  left_join(Mecklenberg) %>%
    st_sf() %>%
    ggplot() + 
      geom_sf(aes(fill = mean.MAPE)) +
      geom_sf(data = bothRegressions, colour = "black", size = .5) +
      facet_wrap(~Regression) +
      scale_fill_gradient(low = palette5[1], high = palette5[5],
                          name = "MAPE") +
      labs(title = "Mean test set MAPE by neighborhood") +
      mapTheme()
```

```{r,include=FALSE}
CHALLENGE <-
  salegroup_challenge %>%
  mutate(Regression = "Neighborhood Effects",
         SalePrice.Predict = predict(reg.nhood, salegroup_challenge),
        )%>%
  st_drop_geometry%>%
  rename(prediction = SalePrice.Predict)%>%
subset(select=c("musaID","prediction"))

write.csv(CHALLENGE,"SY_group_prediction_2.csv", row.names = FALSE)
```



# Discussion

By thinking the variables of internal characteristics, external amenities and spatial factors and doing feature engineering, we build our sketch model. Considering the spatial lag could significantly increase the model accuracy and decrease our sale price APE.

However, our model is still not accurate enough to help Zillow to predict the housing price, since our MAE is around $95,800, which means a big gap between the predicted and real price.

 It is interesting for us to learn that “units” is a critical variable to improve the model. For the external amenities, it is proved that the landfill facilities do negative impact on housing price and proximity to bus stops increase price as we thought. But it is also surprising for us to see some external variables like school, park and station don’t seem attractive to people and even have negative impact on housing price, which worth further study.

The barriers for us probably include not identifying some key internal characteristics variables and not having access to some external data like crime data and school district data, which we believe would improve our price prediction model a lot.


# Conclusion

Although some features in our model show strong correlation with the housing price, there is still a room to improve our model considering the MAE, MAPE and r-squared. We could consider inviting more data to improve the model. Also, non-linear models other OLS can be considered for better fit.