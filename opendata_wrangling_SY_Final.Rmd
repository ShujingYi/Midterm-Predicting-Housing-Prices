---
title: "Predicting Housing Prices"
author: "Shujing Yi & Yuehui Gong"
date: '2022-10-10'
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

```{r, include=FALSE}
## Quick fix for stargazer <= 5.2.3 is.na() issue with long model names in R >= 4.2
# Unload stargazer if loaded
#detach("package:stargazer",unload=T)
# Delete it
remove.packages("stargazer")
# Download the source
download.file("https://cran.r-project.org/src/contrib/stargazer_5.2.3.tar.gz", destfile = "stargazer_5.2.3.tar.gz")
# Unpack
untar("stargazer_5.2.3.tar.gz")
# Read the sourcefile with .inside.bracket fun
stargazer_src <- readLines("stargazer/R/stargazer-internal.R")
# Move the length check 5 lines up so it precedes is.na(.)
stargazer_src[1990] <- stargazer_src[1995]
stargazer_src[1995] <- ""
# Save back
writeLines(stargazer_src, con="stargazer/R/stargazer-internal.R")
# Compile and install the patched package
install.packages("stargazer", repos = NULL, type="source")
```

# Introduction

As Zillow has realized that its housing market predictions are not as
accurate as they could be because they do not factor in enough local
intelligence in Mecklenburg, this project is to improve Zillow's housing
market predictions for Mecklenburg.

To build a better housing price prediction regression model, our model
includes three types of variables: external amenities, internal
characteristics of houses from the given housing price dataset, and
services from open data source, and spatial factors.

## Setup

```{r setup_set}

# You can set some global options for knitting chunks

knitr::opts_chunk$set(echo = TRUE)

# Load some libraries
library(tidyverse)
library(raster)
library(tidycensus)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
library(stargazer)

# functions and data directory
root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"

source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")

palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
```

# Data Wrangling and Feature Engineering

The given housing price dataset includes the housing price and internal
characteristics information for each housing point. It is input as the
base dataset for further feather engineering.

```{r, results='hide'}
sale <- 
  st_read("data/studentData.geojson") %>%
  st_transform('ESRI:102286')

```

```{r, results='hide'}
Mecklenberg <- 
  st_read("data/zipcode/zipcode.shp") %>%
  st_transform('ESRI:102286')
```

The following map visualize the distribution of housing points and their
prices, which is represented in color.

It is clear the housing price distribution shows spatial clustering: the
houses with high price, represented in orange, mainly distribute in the
southern neighborhoods and other clusters near the county boundary.

```{r}
ggplot() +
  geom_sf(data=Mecklenberg,fill = "grey40", color = "grey10",size= 0.7)+
  geom_sf(data = sale, aes(colour = q5(as.numeric(price))), 
          show.legend = "point", size = .75) +
  scale_colour_manual(values = palette5,
                   labels=qBr(sale,"price"),
                   name="Quintile\nBreaks") +
  labs(title="Home Price, Mecklenburg")

```

## External Amenities

The first part of variables our model is to use the external amenities,
the proximity to which could add value to houses. To get the data, we
are using the open data portal for Mecklenburg.
(<http://maps.co.mecklenburg.nc.us/openmapping/data.html>)

Our model is considering the following amenities and services: -Public
Transportation: bus stop, station -Public Amenities: park, school
-Potential negative factors: homeless shelter, flood, Landfill

### Bus Stop

As part of the public transportation system, being close to bus stops
might add value to housing price. The following map shows the bus stops
in Mecklenburg.

```{r, results='hide'}
busstop <- st_read("data/cats_busstops/CATS_BusStops.shp") #%>%
#st_transform(st_crs(tracts20))
ggplot() +
 geom_sf(data=Mecklenberg,fill = "white", color = "grey60",size= 0.5)+
  geom_sf(data = busstop,size= 0.3)+
    labs(title = "Bus Stops, Mecklenburg")
  
```

The distance from each house to the nearest bus stop is calculated as
"bus_nn1", which could be one important external variables for our
model.

```{r}
sale <-
  sale %>% 
    mutate(bus_nn1 = nn_function(st_coordinates(sale), st_coordinates(busstop), 1))

```

### Station

Similar to bus stops, metro station is a significant part of
transportation service. The following map shows the station stops in
Mecklenburg and "station_nn1" is measured as the nearest distance from
house to metro station.

```{r, results='hide'}
station<- st_read("data/station_merge/station_merge.shp") 
ggplot() +
 geom_sf(data=Mecklenberg,fill = "white", color = "grey60",size= 0.5)+
    geom_sf(data = station) +
    labs(title = "Stations, Mecklenburg")

```

```{r}
sale <-
  sale %>% 
    mutate(station_nn1 = nn_function(st_coordinates(sale), st_coordinates(station), 1))

```

### Park

Park is serving as a public amenities for people's daily recreation, as
is shown in the following density map, and the distance to park could be
considered. Thus, we are calculating the distance to the nearest park as
"park_nn1" and mean distance to the 3 nearest parks as "park_nn3".
Further analysis would be down to select the more effective variable.

```{r, results='hide'}
park <- st_read("data/park_locations/Park_Locations.shp") %>%
              st_transform(st_crs(Mecklenberg)) 


ggplot() + geom_sf(data=Mecklenberg,fill = "white", color = "grey60",size= 0.5)+
  stat_density2d(data = data.frame(st_coordinates(park)), 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.01, bins = 40, geom = 'polygon') +
  scale_fill_gradient(low = "#25CB10", high = "#FA7800", 
                      breaks=c(0.000000003,0.00000003),
                      labels=c("Minimum","Maximum"), name = "Density") +
  scale_alpha(range = c(0.00, 0.35), guide = FALSE) +
  labs(title = "Density of Parks, Mecklenburg") 

```

```{r}
sale <-
  sale %>% 
    mutate(park_nn1 = nn_function(st_coordinates(sale), st_coordinates(park), 1),
           park_nn3 = nn_function(st_coordinates(sale), st_coordinates(park), 3))

```

### School

Also as an important amenity, we are using public school point data,
including elementary, middle, high school and charter school. It might
be more helpful to think of school district data, but it is not
available from the open data source.

```{r, results='hide'}
school_public <- st_read("data/cms_schools/CMS_Schools.shp") %>%
              st_transform(st_crs(Mecklenberg)) %>%
  dplyr::select(city, address)

school_charter <- st_read("data/schools_charter/Schools_Charter.shp") %>%
              st_transform(st_crs(Mecklenberg)) %>%
    dplyr::select(city, address)


school<-rbind(school_public,school_charter)

ggplot()+
    geom_sf(data=Mecklenberg,fill = "white", color = "grey60",size= 0.5)+  
  geom_sf(data=school)+
    labs(title = "Public Schools in Mecklenburg") 
```

"school_nn1", "school_nn2", "school_nn3" are calculated as the mean
distance to the nearest, 2 nearest and 3 nearest schools from each
housing points.

```{r}
sale <-
  sale %>% 
    mutate(school_nn1 = nn_function(st_coordinates(sale), st_coordinates(school), 1),
   school_nn2 = nn_function(st_coordinates(sale), st_coordinates(school), 2),   
   school_nn3 = nn_function(st_coordinates(sale), st_coordinates(school), 3))
```

### Homeless Shelter

Homeless shelters is part of the potential negative factors, which are
mainly located at the center of Mecklenberg county. Thus, the proximity
to homeless shelter is calculated as "homelessshelter_nn1".

```{r, results='hide'}
homelessshelter <- st_read("data/homeless_shelters/Homeless_Shelters.shp") %>%
              st_transform(st_crs(Mecklenberg)) 
ggplot() +
  geom_sf(data=Mecklenberg,fill = "white", color = "grey60",size= 0.5)+
  geom_sf(data = homelessshelter, fill = "red")+ 
  labs(title = "Homeless Shelter in Mecklenburg")



sale <-
  sale %>% 
    mutate(homelessshelter_nn1 = nn_function(st_coordinates(sale), st_coordinates(homelessshelter), 1))
```

### Landfill

Another potential negative factor which might impact the housing price
is the landfill. The landfill parcels are visualized in the map.

```{r, results='hide'}
landfill <- st_read("data/landfills/Landfills.shp") %>%
              st_transform(st_crs(Mecklenberg)) 


ggplot() +
  geom_sf(data=Mecklenberg,fill = "white", color = "grey60",size= 0.5)+  
  geom_sf(data = landfill, fill = "red", color = "transparent") +
   labs(title = "Landfill in Mecklenburg") 

```

To do the feature engineering, we use st_centroid to extract the center
points and then calculate the nearest distance from houses to landfill
center points.

```{r}
sale <-
  sale %>% 
    mutate(landfill = nn_function(st_coordinates(sale), st_coordinates(st_centroid(landfill)), 1))
```

### Floodplain

We find flooding might be another concern when people are buying their
houses, which means whether or not the houses are within the 100 year
floodplain could a significant variable for our model. The map shows the
100 year floodplain along the water way.

```{r, results='hide'}
flood100y <- st_read("data/femaexisting_100yr_floodplain/FEMAExisting_100yr_Floodplain.shp") %>%
              st_transform(st_crs(Mecklenberg)) 
ggplot() +
  geom_sf(data=Mecklenberg,fill = "white", color = "grey60",size= 0.5)+  
  geom_sf(data = flood100y, fill = "dark blue",color="transparent") +
  labs(title = "100 year Floodplain in Mecklenburg") 
```

Then we map the houses within the floodplain in red in the following
map. We create a binary variable called "flood100y" to assign "1" to
houses within the floodplain and "0" to houses that will not be impacted
by 100 year flood.

```{r}
salegroup <- 
  rbind(
    sale[flood100y,] %>%
      st_drop_geometry() %>%
      left_join(sale) %>%
      st_sf() %>%
      mutate(flood100y = 1),
   sale[flood100y, op = st_disjoint] %>%
      st_drop_geometry() %>%
      left_join(sale) %>%
      st_sf() %>%
      mutate(flood100y = 0))

salegroup <- salegroup[!duplicated(salegroup$musaID), ]  

```

```{r}
floodpt<-
  salegroup %>%
  filter(flood100y == 1)

ggplot() +
  geom_sf(data=Mecklenberg,fill = "white", color = "grey60",size= 0.5)+  
  geom_sf(data = flood100y, fill = "dark blue",color="transparent") +
     geom_sf(data = salegroup,  col = "grey80",
          show.legend = "point", size = .2) +
  geom_sf(data = floodpt, col = "red",
          show.legend = "point", size = .7) +
  labs(title = "Houses within 100 year Floodplain in Mecklenburg") 


```

## Internal Characteristics

The second part of variables for our model is the internal
characteristics, which are the variables of the housing characteristics
from the given housing data.

The following is the variables to consider: -Heated area -Bedrooms -Full
baths -Half baths -Housing age -Housing story height -Fire place number
-Foundation types -Heated fuel types -Architecture types -Units -Account
types

In this part, we are doing feature engineering to either transform
numeric variables to categorical variables or recategorize the
categorical variables to increase the model accuracy.

### Categorical Bar Plot

To identify the categorical variables which have high correlation with
price, we first make the bar plots showing price as a function of
categorical variables.

```{r fig.height=8, fig.width=12}
st_drop_geometry(salegroup) %>% 
  dplyr::select(price, descbuildi, storyheigh, aheatingty, heatedfuel,actype,extwall,foundation, bldggrade,
                ) %>%
  filter(price <= 1000000) %>%
  gather(Variable, Value, -price) %>% 
   ggplot(aes(Value, price)) +
     geom_bar(position = "dodge", stat = "summary", fun.y = "mean") +
     facet_wrap(~Variable, ncol = 4, scales = "free") +
     labs(title = "Price as a function of\ncategorical variables", y = "Mean_Price") +
     plotTheme() + theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

It shows that the variables of architecture type, building grade, heated
fuel type and story height are all correlated with sale price and they
can be our potential variables.

### Age

One key characteristics of a house to consider is its age. We first
calculate the age (age = 2022 - yearbuilt).

```{r}
salegroup <- 
  salegroup %>%
  mutate(age = 2022 - yearbuilt)
```

```{r}
s <-salegroup %>% 
  filter(age <= 200) 
histogram(s$age,main="Housing Age Histogram",breaks=40,col = c("grey50"))

```

The age now is a numeric variable, which doesn't correlate strongly with
the price. To transform them into categorical variables, we want to
identify the different ranges to categorize the age variable, so we make
this histogram. Based on the age histogram, we decide to categorize the
age into four ranges in "age.cat" variable:

age \>= 0 & age \<15 \~ "Up to 15yrs", age \>= 15 & age \< 50 \~
"15-50yrs", age \>= 50 & age \< 75 \~ "50-75yrs",\
age \>= 75 \~ "75+yrs"

```{r}
salegroup <- 
  salegroup %>%
  mutate(age.cat = case_when(
                  age >= 0 & age <15  ~ "Up to 15yrs",
                  age >= 15 & age < 50  ~ "15-50yrs",
                  age >= 50 & age < 75  ~ "50-75yrs",                   
                  age >= 75  ~ "75+yrs"),)
```

### Story Height

We think it might be helpful to recategorize the story height class. So
we use "recode" to get the "story.cat" variable of 5 class:

"1.0 STORY"= "1story","1 STORY"= "1story" "1.5 STORY" = "2story", "2.0
STORY" = "2story","BI-LEVEL"="2story","SPLIT LEVEL"="2story" "2.5
STORY"="3story","3.0 STORY"="3story" "CAPE COD"="other","RANCH
W/BSMT"="other" "\>=4story"

```{r,results='hide'}
glimpse(s$storyheigh)


salegroup$story.cat <- recode(salegroup$storyheigh,"1.0 STORY"= "1story","1 STORY"= "1story", "1.5 STORY" = "2story", "2.0 STORY" = "2story","BI-LEVEL"="2story","SPLIT LEVEL"="2story","2.5 STORY"="3story","3.0 STORY"="3story","CAPE COD"="other","RANCH W/BSMT"="other")

```

## Spatial Factors

### Census Tract

To take spatial clustering into consideration, we then use census tract
data and neighborhood effect as the spatial factors to help the model
better understand the spatial clustering.

By importing the census tract data, we collect the total population,
white population, female bachelors, male bachelors, median income,
median rent, total poverty.

We then calculate the variables of white population percentage, bachelor
percentage, poverty percentage to make it easier to do the comparison
among census tracts.

```{r, results='hide'}
census_api_key("a78f5d0c0fd577cd3f16136b5a87d6ecdb62ffba", overwrite = TRUE)

tracts <-  
  get_acs(geography = "tract",
          variables = c("B25026_001E","B02001_002E",
                        "B15001_050E","B15001_009E",
                        "B19013_001E", "B25058_001E",
                        "B06012_002E"), 
          year=2020, state="NC",
          county="Mecklenburg County", geometry=TRUE) %>% 
  st_transform('ESRI:102286')

```

```{r}
tracts <- 
  tracts %>%
  dplyr::select( -NAME, -moe) %>%
  spread(variable, estimate) %>%
  rename(TotalPop = B25026_001, 
         Whites = B02001_002,
         FemaleBachelors = B15001_050, 
         MaleBachelors = B15001_009,
         MedHHInc = B19013_001, 
         MedRent = B25058_001,
         TotalPoverty = B06012_002)

tracts <- 
  tracts %>%
  mutate(pctWhite = ifelse(TotalPop > 0, Whites / TotalPop, 0),
         pctBachelors = ifelse(TotalPop > 0, ((FemaleBachelors + MaleBachelors) / TotalPop), 0),
         pctPoverty = ifelse(TotalPop > 0, TotalPoverty / TotalPop, 0)) %>%
  dplyr::select(-Whites,-FemaleBachelors,-MaleBachelors,-TotalPoverty)
```

```{r}
ggplot()+
  geom_sf(data = tracts, fill = "white", color = "black")+
  geom_sf(data=salegroup, 
          show.legend = "point", size= 0.1) +
  labs(title = "Mecklenburg Census Tracts") +
  theme(plot.title = element_text(size=22))
```

```{r}

A2<-
  ggplot() +
  geom_sf(data = tracts, aes(fill = pctWhite)) +
  labs(title = "White Percentage", subtitle = "Mecklenburg, 2020") +
  theme(plot.title = element_text(size=22))
A3<-
  ggplot() +
  geom_sf(data = tracts, aes(fill = MedHHInc)) +
  labs(title = "Median Income", subtitle = "Mecklenburg, 2020") +
  theme(plot.title = element_text(size=22))
grid.arrange(A2,A3, nrow = 1)
```

So following is the spatial variables for our model:

-White percentage -Bachelor percentage -Poverty percentage -Median
income -Median rent

```{r}
salegroup<-st_intersection(salegroup,tracts)

```

```{r}
salegroup<-st_intersection(salegroup,Mecklenberg)
```

## Table of summary statistics

```{r}
stargazer(as.data.frame(salegroup[c("price","heatedarea","bedrooms","fullbaths","halfbaths","numfirepla","foundation","heatedfuel","actype","units","accounttyp","shape_Area")]), type="text", 
          title="Internal Characteristics", digits=1)
```

```{r}
stargazer(as.data.frame(salegroup[c("park_nn1","homelessshelter_nn1","landfill","flood100y","school_nn1","bus_nn1","station_nn1")]), type="text", 
          title="Amenities/public Services", digits=1)
```

```{r}
stargazer(as.data.frame(salegroup[c("TotalPop","pctWhite","pctBachelors","pctPoverty", "MedHHInc")]), type="text", 
          title="Spatial Structure", digits=1)
```

```{r}
salegroup_challenge <- salegroup %>%
  filter (salegroup$toPredict == "CHALLENGE")
salegroup <- salegroup %>%
  filter (salegroup$toPredict == "MODELLING")

```

## Home Price Correlation Scatter Plots

To understand how some of the continuous variables correlate with
housing price, we get the correlation scatter plots.

```{r}
st_drop_geometry(salegroup) %>% 
  dplyr::select(price,park_nn1,landfill,flood100y,MedHHInc) %>%
  filter(price <= 1000000) %>%
  gather(Variable, Value, -price) %>% 
  
   ggplot(aes(Value, price)) +
     geom_point(size = .5) + geom_smooth(method = "lm", se=F, colour = "#FA7800") +
     facet_wrap(~Variable, ncol = 2, scales = "free") +
     labs(title = "Price as a function of continuous variables") +
     plotTheme()
```

For the 100 year flood and landfill, it makes sense that the further
distance to landfills the higher housing price will be and but it is
strange to see that the houses in floodplain have slightly higher price.

For the park, the scatter plot shows that the closer to the parks, the
more expensive the houses would be, which proves that parks could be an
attractive public amenity. It is also not surprising that median income
of census tract has high correlation with housing price spatially.

## Correlation Matrix

Correlation matrix is produced to see the relationship between the
continuous variables.Three separate correlation matrix are made for each
part of our variables. To further simplify the correlation plot, only
one variable is kept for each amenity.

```{r}
numericVars <- 
  select_if(st_drop_geometry(salegroup), is.numeric) %>% na.omit()%>%
  dplyr::select(price,heatedarea,bedrooms,fullbaths,numfirepla,units)

ggcorrplot(
  round(cor(numericVars), 1), 
  p.mat = cor_pmat(numericVars),
  colors = c("#25CB10", "white", "#FA7800"),
  type="lower",
  insig = "blank") +  
    labs(title = "Correlation across numeric variables: Internal Characteristics") 
```

```{r}
numericVars <- 
  select_if(st_drop_geometry(salegroup), is.numeric) %>% na.omit()%>%
  dplyr::select(price,park_nn1,homelessshelter_nn1,landfill,flood100y,school_nn1,bus_nn1,station_nn1)

ggcorrplot(
  round(cor(numericVars), 1), 
  p.mat = cor_pmat(numericVars),
  colors = c("#25CB10", "white", "#FA7800"),
  type="lower",
  insig = "blank") +  
    labs(title = "Correlation across numeric variables: External Amenities") 
```

```{r}
numericVars <- 
  select_if(st_drop_geometry(salegroup), is.numeric) %>% na.omit()%>%
  dplyr::select(price,TotalPop,pctWhite,pctBachelors,pctPoverty, MedHHInc)

ggcorrplot(
  round(cor(numericVars), 1), 
  p.mat = cor_pmat(numericVars),
  colors = c("#25CB10", "white", "#FA7800"),
  type="lower",
  insig = "blank") +  
    labs(title = "Correlation across numeric variables: Census Tract data") 
```

# Methods

After data wrangling and feature engineering, we build our regression
model. Linear Regression, or Ordinary Least Squares Regression (OLS), is
used to predict the price of a house as a function of several
components.

In the result of a regression model, the p-value is a direct way to
measure if the coefficient is reliable and is a standard measure of
statistical significance. (Adjusted) R\^2 is a standard regression
'goodness of fit' indicator that describes how well the features explain
the outcome.

For this project, we attempted to maximize our model's generalizability.
We randomly split our data into training and stretching sets to test our
models' generalizability. Then we performed regressions, adding one
dependent variable at a time and determining whether the model's mean
absolute error (MAE) and R\^2 went up or down.

# Results

## Split dataframe into training and testing datasets

Below, after selecting all the "MODELLING" data from our
dataset,salegroup was split into a 60% Mecklenberg.training dataset and
a 40% Mecklenberg.test dataset, with control to include all levels of
categorical variables (storyheigh, age.cat, heatedfuel, actype, etc.).

```{r}
set.seed(5)
inTrain <- createDataPartition(
              y = paste(salegroup$storyheigh,salegroup$age.cat,salegroup$heatedfuel, salegroup$actype,salegroup$foundation,salegroup$accounttyp), 
              p = .60, list = FALSE)
Mecklenberg.training <- salegroup[inTrain,] 
Mecklenberg.test <- salegroup[-inTrain,]  
```

## training set regression

The output below is a summary of our model. The summary of r-squared and adjusted r-squared for the training sample is also demonstrated below. Generally, about 68% of the variance of the dependent variable is explained in this prediction.

```{r}
reg.training <- lm(price ~ ., data = st_drop_geometry(Mecklenberg.training) %>% 
                                 dplyr::select(price, heatedarea, bedrooms, 
                                               age.cat,storyheigh,fullbaths, halfbaths,
                                               numfirepla,foundation,heatedfuel,units,accounttyp, park_nn1,homelessshelter_nn1,landfill,flood100y,school_nn1,bus_nn1,station_nn1,bldggrade,
                                               TotalPop,pctWhite,pctBachelors,pctPoverty,MedHHInc,zip,shape_Area))

stargazer(reg.training, type="text", digits=3)
```

## Test Set

In this test set, the mean absolute error is 112144, while the Mean Absolute Percent Error is about 28%.

```{r}
Mecklenberg.test <-
  Mecklenberg.test %>%
  mutate(Regression = "Baseline Regression",
         SalePrice.Predict = predict(reg.training, Mecklenberg.test),
         SalePrice.Error = SalePrice.Predict - price,
         SalePrice.AbsError = abs(SalePrice.Predict - price),
         SalePrice.APE = (abs(SalePrice.Predict - price)) / SalePrice.Predict)%>%
  filter(price < 5000000) 
```

```{r}


data.frame(Mean_Absolute_Error = mean(Mecklenberg.test$SalePrice.AbsError, na.rm = T),
           Mean_Absolute_Percent_Error =mean(Mecklenberg.test$SalePrice.APE, na.rm = T))%>%
  kable() %>%
  kable_styling() 
```

```{r}
ggplot() +
  geom_sf(data=Mecklenberg,fill = "grey40", color = "grey10",size= 0.7)+
  geom_sf(data = Mecklenberg.test, aes(colour = q5(as.numeric(SalePrice.AbsError))), 
          show.legend = "point", size = .75) +
  scale_colour_manual(values = palette5,
                   labels=qBr(sale,"price"),
                   name="Quintile\nBreaks") +
  labs(title="Home Price Absolute Error, Mecklenberg") +
  mapTheme()
```

## Cross validation


```{r}
fitControl <- trainControl(method = "cv", number = 100)
set.seed(825)

reg.cv <- 
  train(price ~ ., data = st_drop_geometry(salegroup) %>% 
                                dplyr::select(price, heatedarea, bedrooms, 
                                               age.cat,storyheigh,fullbaths,halfbaths,
                                               numfirepla,foundation,heatedfuel,units,accounttyp, park_nn1,homelessshelter_nn1,landfill,flood100y,school_nn1,bus_nn1,station_nn1,bldggrade,
                                               TotalPop,pctWhite,pctBachelors,pctPoverty,MedHHInc,zip,shape_Area), 
     method = "lm", trControl = fitControl, na.action = na.pass)

reg.cv
```

```{r goodness_metrics, message = FALSE, warning = FALSE}
dplyr::select(reg.cv$resample, -Resample) %>%
  gather(metric, value) %>%
  left_join(gather(reg.cv$results[2:4], metric, mean)) %>%
  ggplot(aes(value)) + 
    geom_histogram(bins=35, fill = "#FF006A") +
    facet_wrap(~metric,scales = "free_x") +
    geom_vline(aes(xintercept = mean), colour = "#981FAC", linetype = 3, size = 1.5) +

    labs(x="Goodness of Fit", y="Count", title="CV Goodness of Fit Metrics",
         subtitle = "Across-fold mean reprented as dotted lines")

```

## Map of Predicted Values

```{r}
CHALLENGE <-
  salegroup_challenge %>%
  mutate(Regression = "Neighborhood Effects",
         SalePrice.Predict = predict(reg.training, salegroup_challenge),
        )%>%
  rename(prediction = SalePrice.Predict)


MODELLING <-
  salegroup %>%
  mutate(Regression = "Neighborhood Effects",
         SalePrice.Predict = predict(reg.training, salegroup),
        )%>%
  rename(prediction = SalePrice.Predict)

TOTAL <- rbind(CHALLENGE, MODELLING )
  
```

```{r}
ggplot() +
  geom_sf(data=Mecklenberg,fill = "grey40", color = "grey10",size= 0.7)+
  geom_sf(data = TOTAL, aes(colour = q5(as.numeric(prediction))), 
          show.legend = "point", size = .75) +
  scale_colour_manual(values = palette5,
                   labels=qBr(TOTAL,"prediction"),
                   name="Quintile\nBreaks") +
  labs(title="Home Price prediction, Mecklenburg")

```

## Predicted Prices as a Function of Observed Prices
As we analyze the test set which occupied 40% of the total set, the prediction model still has some inaccuracy. The graphic below shows the sale price compared with the price prediction.

```{r}
Mecklenberg.test %>%
  dplyr::select(SalePrice.Predict, price) %>%
    ggplot(aes(price, SalePrice.Predict)) +
  geom_point() +
  stat_smooth(aes(price, price), 
             method = "lm", se = FALSE, size = 1, colour="#FA7800") + 
  stat_smooth(aes(SalePrice.Predict, price), 
              method = "lm", se = FALSE, size = 1, colour="#25CB10") +
  labs(title="Predicted sale price as a function of observed price",
       subtitle="Orange line represents a perfect prediction; Green line represents prediction") +
  plotTheme()


```

## Spatial Correlation of error
The plots show that as the price increases, so does the price of nearby houses. This is substantial evidence for the clustering of home prices. As home price errors increase, nearby home price errors decrease. 
```{r}
coords.test <- st_coordinates(Mecklenberg.test) 

neighborList.test <- knn2nb(knearneigh(coords.test, 5))

spatialWeights.test <- nb2listw(neighborList.test, style="W")

Mecklenberg.test$lagPrice <- lag.listw(spatialWeights.test, Mecklenberg.test$price)
Mecklenberg.test$lagPriceError<-lag.listw(spatialWeights.test, Mecklenberg.test$SalePrice.Error, NAOK = TRUE)

#Mecklenberg.test %>% 
  #mutate(lagPriceError = lag.listw(spatialWeights.test, SalePrice.Error, NAOK = TRUE)) %>%
  #ggplot(aes(lagPriceError, SalePrice.Error))

```

```{r}
ggplot(Mecklenberg.test, aes(x=lagPrice, y=price)) +
  geom_point(colour = "#FA7800") +
  geom_smooth(method = "lm", se = FALSE, colour = "#25CB10") +
  labs(title = "Price as a function of the spatial lag of price",
       caption = "Figure 4.2",
       x = "Spatial lag of price (Mean price of 5 nearest neighbors)",
       y = "Sale Price") +
  plotTheme()
```

```{r}
ggplot(Mecklenberg.test, aes(x=lagPriceError, y=price)) +
  geom_point(colour = "#FA7800") +
  geom_smooth(method = "lm", se = FALSE, colour = "#25CB10") +
  labs(title = "Error as a function of the spatial lag of price",
       caption="Figure 4.3",
       x = "Spatial lag of errors (Mean error of 5 nearest neighbors)",
       y = "Sale Price") +
  plotTheme()
```

## Moran's
The frequency of all 999 randomly permutated I are plotted as a histogram with the Observed I indicated by the orange line. That the observed I is higher than all of the 999 randomly generated I’s provides visual confirmation of spatial autocorrelation. 

```{r}
moranTest <- moran.mc(Mecklenberg.test$SalePrice.Error, 
                      spatialWeights.test, nsim = 999, na.action=na.omit)

ggplot(as.data.frame(moranTest$res[c(1:999)]), aes(moranTest$res[c(1:999)])) +
  geom_histogram(binwidth = 0.01) +
  geom_vline(aes(xintercept = moranTest$statistic), colour = "#FA7800",size=1) +
  scale_x_continuous(limits = c(-1, 1)) +
  labs(title="Observed and permuted Moran's I",
       subtitle= "Observed Moran's I in orange",
       x="Moran's I",
       y="Count") +
  plotTheme()
```

## Accounting for neighborhood

```{r}
# Errors by neighborhood
left_join(
  st_drop_geometry(Mecklenberg.test) %>%
    group_by(zip) %>%
    summarize(meanPrice = mean(price, na.rm = T)),
  mutate(Mecklenberg.test, predict.fe = 
                        predict(lm(price ~ zip, data = Mecklenberg.test), 
                        Mecklenberg.test)) %>%
    st_drop_geometry %>%
    group_by(zip) %>%
      summarize(meanPrediction = mean(predict.fe))) %>%
      kable() %>% kable_styling()
```

## Accuracy of the neighborhood mode
It is clear our model is relatively consistent across the neighborhoods. We can conclude that our model is generalizable. The single neighborhood that has super high sale prices should be treated as an outlier.

```{r}
  
st_drop_geometry(Mecklenberg.test) %>%
  group_by(zip) %>%
  summarize(mean.MAPE = mean(SalePrice.APE, na.rm = T)) %>%
  ungroup() %>% 
  left_join(Mecklenberg) %>%
    st_sf() %>%
    ggplot() + 
      geom_sf(aes(fill = mean.MAPE)) +
      geom_sf(data = Mecklenberg.test, colour = "black", size = .5) +
      scale_fill_gradient(low = palette5[1], high = palette5[5],
                          name = "MAPE") +
      labs(title = "Mean test set MAPE by neighborhood") +
      mapTheme()
```

```{r}
Mecklenberg_sum <- Mecklenberg.test %>% 
  group_by(zip) %>% 
  summarise(meanMAPE = mean(SalePrice.APE),
            meanPrice = mean(SalePrice.Predict))


ggplot(Mecklenberg_sum, aes(x = meanPrice, y = meanMAPE)) +
  geom_point() +
  geom_smooth(method = "lm", color = "green") +
  labs(title = "Scatter Plot - SalePrice/MAPE by neighborhood",
       x = "Sale Price",
       y = "MAPE") +
  theme(
    legend.position = "none"
  )
```

## Generalizability by Income

Finally, we calculated MAPE for below/above average home income to test the model's generalizability. The results indicate that our model has a slightly higher MAPE in high-income census tracts than in low-income ones, but very close. The model is generalizable.

```{r}
mean(tracts$MedHHInc, na.rm = T)
```

```{r}
tracts <- 
  tracts%>%
  mutate(incomeContext = ifelse(MedHHInc > 77915, "High Income", "Low Income"))

ggplot() + geom_sf(data = na.omit(tracts), aes(fill = incomeContext)) +
    scale_fill_manual(values = c("#25CB10", "#FA7800"), name="Income Context") +
    labs(title = "Income Context") +
    mapTheme() + theme(legend.position="bottom")
```

```{r}
st_join(Mecklenberg.test, tracts) %>% 
  filter(!is.na(incomeContext)) %>%
  group_by(incomeContext) %>%
  summarize(mean.MAPE = scales::percent(mean(SalePrice.APE, na.rm = T))) %>%
  st_drop_geometry() %>%
  spread(incomeContext, mean.MAPE) %>%
  kable(caption = "Test set MAPE by neighborhood income context")
```

# Discussion

We build our sketch model by thinking about the variables of internal characteristics, external amenities, and spatial factors and doing feature engineering. Considering the neighborhood effect could significantly increase the model accuracy and decrease our sale price APE.

However, our model is still not accurate enough to help Zillow to predict the housing price, since our MAE is around $112,144, which means a big gap between the predicted and real price.

It is interesting for us to learn that "units" is a critical variable to improve the model. For the external amenities, it is proved that the landfill facilities do negative impact on housing price and proximity to bus stops increase price as we thought. But it is also surprising for us to see some external variables like school, park and station don't seem attractive to people and even have negative impact on housing price, which worth further study.

The barriers for us probably include not identifying some key internal characteristics variables and not having access to some external data like crime data and school district data, which we believe would improve our price prediction model a lot.

# Conclusion

Although some features in our model show strong correlation with the
housing price, there is still a room to improve our model considering
the MAE, MAPE and r-squared. We could consider inviting more data to
improve the model. Also, non-linear models other OLS can be considered
for better fit.
